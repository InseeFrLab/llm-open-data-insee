{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration de la base de données vectorielle\n",
    "\n",
    "## Récupération de la base de données vectorielle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import DB_DIR_S3, DB_DIR_LOCAL, EMB_MODEL_NAME\n",
    "from utils import loading_utilities\n",
    "\n",
    "loading_utilities.load_chroma_db(\n",
    "    s3_path=f\"s3/projet-llm-insee-open-data/{DB_DIR_S3}\", persist_directory=DB_DIR_LOCAL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient(path=DB_DIR_LOCAL)\n",
    "collection = client.get_collection(\"insee_data\")\n",
    "collection.get(\n",
    "    include=[\"metadatas\", \"documents\", \"embeddings\"],\n",
    "    limit=1,\n",
    ")\n",
    "collection.get(include=[\"metadatas\"], limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(\"Quelle est la définition du PIB ?\", k=5)\n",
    "docs_dict = [{\"page_content\": doc.page_content, \"metadata\": doc.metadata} for doc in docs]\n",
    "docs_data = pd.json_normalize(docs_dict)\n",
    "docs_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avec langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from config import EMB_DEVICE\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(  # load from sentence transformers\n",
    "    model_name=EMB_MODEL_NAME,\n",
    "    model_kwargs={\"device\": EMB_DEVICE},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},  # set True for cosine similarity\n",
    "    show_progress=False,\n",
    ")\n",
    "\n",
    "vectordb = Chroma(\n",
    "    collection_name=\"insee_data\", persist_directory=DB_DIR_LOCAL, embedding_function=embedding_model\n",
    ")\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from config import EMB_MODEL_NAME, DB_DIR_S3\n",
    "from db_building import build_database_from_csv\n",
    "\n",
    "# Global parameters\n",
    "EXPERIMENT_NAME = \"BUILD_CHROMA_TEST\"\n",
    "MAX_NUMBER_PAGES = 100\n",
    "CHROMA_DB_LOCAL_DIRECTORY = \"data/chroma_database/chroma_test/\"\n",
    "path_s3 = f\"s3/projet-llm-insee-open-data/{DB_DIR_S3}\"\n",
    "\n",
    "path_s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "EXPERIMENT_NAME = \"BUILD_CHROMA_TEST\"\n",
    "MAX_NUMBER_PAGES = 100\n",
    "CHROMA_DB_LOCAL_DIRECTORY = \"data/chroma_database/chroma_test/\"\n",
    "\n",
    "# Rustine temporaire\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"https://projet-llm-insee-open-data-mlflow.user.lab.sspcloud.fr\"\n",
    "\n",
    "# Check mlflow URL is defined\n",
    "assert (\n",
    "    \"MLFLOW_TRACKING_URI\" in os.environ\n",
    "), \"Please set the MLFLOW_TRACKING_URI environment variable.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = build_database_from_csv(\n",
    "    \"../data_complete.csv\",\n",
    "    persist_directory=CHROMA_DB_LOCAL_DIRECTORY,\n",
    "    max_pages=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(db.get()[\"documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from config import EMB_MODEL_NAME, EMB_DEVICE\n",
    "\n",
    "CHROMA_DB_LOCAL_DIRECTORY = \"data/chroma_database/chroma_test/\"\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(  # load from sentence transformers\n",
    "    model_name=EMB_MODEL_NAME,\n",
    "    model_kwargs={\"device\": EMB_DEVICE},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},  # set True for cosine similarity\n",
    "    show_progress=False,\n",
    ")\n",
    "\n",
    "vectordb = Chroma(\n",
    "    collection_name=\"insee_data\",\n",
    "    persist_directory=CHROMA_DB_LOCAL_DIRECTORY,\n",
    "    embedding_function=embedding_model,\n",
    ")\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectordb.get()[\"documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
