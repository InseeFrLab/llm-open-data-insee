{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Recall - Needle-in-a-haystack tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Needle-in-a-Haystack test is designed to evaluate the performance of LLM RAG systems across different sizes of context windows. The testing process is straightforward: it asks an LLM to answer a specific question while the correct information (\"the needle\") is embedded within a large, unrelated context (the haystack).\n",
    "\n",
    "- This test helps to better understand the retrieval abilities of models with very long context windows (some exceeding 200k tokens). Uniform retrieval performance is not guaranteed, as demonstrated in experiments showing that LLM in-context recall is prompt-dependent (see [LLM In-Context Recall is Prompt Dependent](https://arxiv.org/pdf/2404.08865v1))\n",
    "\n",
    "- To our knowledge, this experiment has never been conducted on French statistical data.\n",
    "\n",
    "We will also implement an improvement using multiple facts (needles) to better align with RAG expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will focus on opensource models (no API) and INSEE-related data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]11;?\u001b\\\u001b[6n\u001b[32;1mmc: \u001b[0m\u001b[32;1mConfiguration written to `/home/onyxia/.mc/config.json`. Please update your access credentials.\u001b[0;22m\n",
      "\u001b[32;1mmc: \u001b[0m\u001b[32;1mSuccessfully created `/home/onyxia/.mc/share`.\n",
      "\u001b[0m\u001b[32;1mmc: \u001b[0m\u001b[32;1mInitialized share uploads `/home/onyxia/.mc/share/uploads.json` file.\n",
      "\u001b[0m\u001b[32;1mmc: \u001b[0m\u001b[32;1mInitialized share downloads `/home/onyxia/.mc/share/downloads.json` file.\n",
      "\u001b[0m`s3/projet-llm-insee-open-data/data/eval_data/eval_retrieval/insee_documents_sample_ref_retrieval_evaluation.csv` -> `insee_documents_sample_ref_retrieval_evaluation.csv`\n",
      "Total: 4.69 MiB, Transferred: 4.69 MiB, Speed: 12.72 MiB/s\n"
     ]
    }
   ],
   "source": [
    "! mc cp -q s3/projet-llm-insee-open-data/data/eval_data/eval_retrieval/insee_documents_sample_ref_retrieval_evaluation.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_csv(\"./insee_documents_sample_ref_retrieval_evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>insee_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>date_diffusion</th>\n",
       "      <th>themes</th>\n",
       "      <th>collections</th>\n",
       "      <th>libelleAffichageGeo</th>\n",
       "      <th>intertitres</th>\n",
       "      <th>authors</th>\n",
       "      <th>subtitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L'Insee a conçu une base historique des Recens...</td>\n",
       "      <td>https://www.insee.fr/fr/information/1303688</td>\n",
       "      <td>RP Historiques et Données harmonisées des rece...</td>\n",
       "      <td>1303688</td>\n",
       "      <td>Services</td>\n",
       "      <td>2023-04-25T09:00:14.283Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Description des variables des différents\\n    ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>À l’instar de l’ébéniste, du forgeron ou du ta...</td>\n",
       "      <td>https://www.insee.fr/fr/information/5008707</td>\n",
       "      <td>Qu’est-ce qu’une donnée ?</td>\n",
       "      <td>5008707</td>\n",
       "      <td>Courrier des statistiques</td>\n",
       "      <td>2020-12-31T09:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Les données en statistique La donnée : tentati...</td>\n",
       "      <td>['Pascal Rivière', 'chef de l’Inspection génér...</td>\n",
       "      <td>Impact des données externes sur la statistique...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Les très petites entreprises (TPE) étudiées ic...</td>\n",
       "      <td>https://www.insee.fr/fr/statistiques/4986839</td>\n",
       "      <td>La faiblesse des fonds propres des TPE accroît...</td>\n",
       "      <td>4986839</td>\n",
       "      <td>Publications grand public</td>\n",
       "      <td>2020-12-10T17:00:00Z</td>\n",
       "      <td>['Caractéristiques des entreprises']</td>\n",
       "      <td>Les entreprises en France</td>\n",
       "      <td>France</td>\n",
       "      <td>Les TPE étudiées représentent 38 % des entrepr...</td>\n",
       "      <td>['Noémie Morénillas', 'Gabriel Sklénard (Insee)']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>À l’école, les filles ont de meilleurs résulta...</td>\n",
       "      <td>https://www.insee.fr/fr/statistiques/6047789</td>\n",
       "      <td>Femmes et Hommes: une lente décrue des inégalités</td>\n",
       "      <td>6047789</td>\n",
       "      <td>Publications grand public</td>\n",
       "      <td>2022-03-03T17:00:00Z</td>\n",
       "      <td>['Égalité femmes-hommes']</td>\n",
       "      <td>Femmes et hommes – L’égalité en question</td>\n",
       "      <td>France</td>\n",
       "      <td>À l’école, les filles construisent des parcour...</td>\n",
       "      <td>['Philippe\\xa0Roussel\\xa0(Insee)']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Immigrés et descendants d’immigrés peuvent par...</td>\n",
       "      <td>https://www.insee.fr/fr/statistiques/4175267</td>\n",
       "      <td>Le rôle des origines dans la persistance des i...</td>\n",
       "      <td>4175267</td>\n",
       "      <td>Publications grand public</td>\n",
       "      <td>2019-07-02T16:00:00Z</td>\n",
       "      <td>['Égalité femmes-hommes', 'Emploi – Population...</td>\n",
       "      <td>Emploi, chômage, revenus du travail</td>\n",
       "      <td>France</td>\n",
       "      <td>Résumé Pour les immigrés, les caractéristiques...</td>\n",
       "      <td>['Elika Athari', 'Jérôme Lê (Insee)', 'Yaël Br...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Pour nombre d’enquêtes de la statistique publi...</td>\n",
       "      <td>https://www.insee.fr/fr/information/6035936</td>\n",
       "      <td>La mise en musique d’enquêtes multimodes</td>\n",
       "      <td>6035936</td>\n",
       "      <td>Courrier des statistiques</td>\n",
       "      <td>2022-01-20T10:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pour passer d’un seul mode de collecte à plusi...</td>\n",
       "      <td>['Éric Sigaud', 'maître d’ouvrage délégué du p...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>En France en 2018, 1,9million depersonnes sont...</td>\n",
       "      <td>https://www.insee.fr/fr/statistiques/5371273</td>\n",
       "      <td>Environ 2millions depersonnes en situation de ...</td>\n",
       "      <td>5371273</td>\n",
       "      <td>Publications grand public</td>\n",
       "      <td>2021-05-27T16:00:00Z</td>\n",
       "      <td>['Pauvreté – Précarité']</td>\n",
       "      <td>Les revenus et le patrimoine des ménages</td>\n",
       "      <td>France</td>\n",
       "      <td>La grande pauvreté, cumul de difficultés monét...</td>\n",
       "      <td>['Julien Blasco', 'Sébastien Picard (Insee)']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>En 2019, la France métropolitaine compte 65mil...</td>\n",
       "      <td>https://www.insee.fr/fr/statistiques/4238437</td>\n",
       "      <td>Quarante ans d’évolution de la démographie fra...</td>\n",
       "      <td>4238437</td>\n",
       "      <td>Publications grand public</td>\n",
       "      <td>2019-11-19T17:00:00Z</td>\n",
       "      <td>['Évolution et structure de la population']</td>\n",
       "      <td>France, portrait social</td>\n",
       "      <td>International</td>\n",
       "      <td>Un point sur la démographie française depuis 1...</td>\n",
       "      <td>['Elika Athari', 'Sylvain Papon', 'Isabelle Ro...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>La statistique publique produit des chiffres e...</td>\n",
       "      <td>https://www.insee.fr/fr/information/7635829</td>\n",
       "      <td>L’intégration des données administratives dans...</td>\n",
       "      <td>7635829</td>\n",
       "      <td>Courrier des statistiques</td>\n",
       "      <td>2023-06-30T15:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>La qualification de la source : un pré-requis ...</td>\n",
       "      <td>['Franck Cotton', 'expert', 'DSI', 'Insee', 'f...</td>\n",
       "      <td>Industrialiser une phase essentielle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>La Caisse nationale d’assurance vieillesse (Cn...</td>\n",
       "      <td>https://www.insee.fr/fr/information/6665190</td>\n",
       "      <td>Un référentiel des identités pour les besoins ...</td>\n",
       "      <td>6665190</td>\n",
       "      <td>Courrier des statistiques</td>\n",
       "      <td>2022-11-29T13:30:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Au commencement, connaître les identités pour ...</td>\n",
       "      <td>['Joseph Préveraud de Vaumas', 'Responsable du...</td>\n",
       "      <td>Le système national de gestion des identifiant...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  \\\n",
       "2   L'Insee a conçu une base historique des Recens...   \n",
       "26  À l’instar de l’ébéniste, du forgeron ou du ta...   \n",
       "70  Les très petites entreprises (TPE) étudiées ic...   \n",
       "6   À l’école, les filles ont de meilleurs résulta...   \n",
       "94  Immigrés et descendants d’immigrés peuvent par...   \n",
       "54  Pour nombre d’enquêtes de la statistique publi...   \n",
       "13  En France en 2018, 1,9million depersonnes sont...   \n",
       "29  En 2019, la France métropolitaine compte 65mil...   \n",
       "98  La statistique publique produit des chiffres e...   \n",
       "69  La Caisse nationale d’assurance vieillesse (Cn...   \n",
       "\n",
       "                                          source  \\\n",
       "2    https://www.insee.fr/fr/information/1303688   \n",
       "26   https://www.insee.fr/fr/information/5008707   \n",
       "70  https://www.insee.fr/fr/statistiques/4986839   \n",
       "6   https://www.insee.fr/fr/statistiques/6047789   \n",
       "94  https://www.insee.fr/fr/statistiques/4175267   \n",
       "54   https://www.insee.fr/fr/information/6035936   \n",
       "13  https://www.insee.fr/fr/statistiques/5371273   \n",
       "29  https://www.insee.fr/fr/statistiques/4238437   \n",
       "98   https://www.insee.fr/fr/information/7635829   \n",
       "69   https://www.insee.fr/fr/information/6665190   \n",
       "\n",
       "                                                title  insee_id  \\\n",
       "2   RP Historiques et Données harmonisées des rece...   1303688   \n",
       "26                          Qu’est-ce qu’une donnée ?   5008707   \n",
       "70  La faiblesse des fonds propres des TPE accroît...   4986839   \n",
       "6   Femmes et Hommes: une lente décrue des inégalités   6047789   \n",
       "94  Le rôle des origines dans la persistance des i...   4175267   \n",
       "54           La mise en musique d’enquêtes multimodes   6035936   \n",
       "13  Environ 2millions depersonnes en situation de ...   5371273   \n",
       "29  Quarante ans d’évolution de la démographie fra...   4238437   \n",
       "98  L’intégration des données administratives dans...   7635829   \n",
       "69  Un référentiel des identités pour les besoins ...   6665190   \n",
       "\n",
       "                   categories            date_diffusion  \\\n",
       "2                    Services  2023-04-25T09:00:14.283Z   \n",
       "26  Courrier des statistiques      2020-12-31T09:00:00Z   \n",
       "70  Publications grand public      2020-12-10T17:00:00Z   \n",
       "6   Publications grand public      2022-03-03T17:00:00Z   \n",
       "94  Publications grand public      2019-07-02T16:00:00Z   \n",
       "54  Courrier des statistiques      2022-01-20T10:00:00Z   \n",
       "13  Publications grand public      2021-05-27T16:00:00Z   \n",
       "29  Publications grand public      2019-11-19T17:00:00Z   \n",
       "98  Courrier des statistiques      2023-06-30T15:00:00Z   \n",
       "69  Courrier des statistiques      2022-11-29T13:30:00Z   \n",
       "\n",
       "                                               themes  \\\n",
       "2                                                 NaN   \n",
       "26                                                NaN   \n",
       "70               ['Caractéristiques des entreprises']   \n",
       "6                           ['Égalité femmes-hommes']   \n",
       "94  ['Égalité femmes-hommes', 'Emploi – Population...   \n",
       "54                                                NaN   \n",
       "13                           ['Pauvreté – Précarité']   \n",
       "29        ['Évolution et structure de la population']   \n",
       "98                                                NaN   \n",
       "69                                                NaN   \n",
       "\n",
       "                                 collections libelleAffichageGeo  \\\n",
       "2                                        NaN                 NaN   \n",
       "26                                       NaN                 NaN   \n",
       "70                 Les entreprises en France              France   \n",
       "6   Femmes et hommes – L’égalité en question              France   \n",
       "94       Emploi, chômage, revenus du travail              France   \n",
       "54                                       NaN                 NaN   \n",
       "13  Les revenus et le patrimoine des ménages              France   \n",
       "29                   France, portrait social       International   \n",
       "98                                       NaN                 NaN   \n",
       "69                                       NaN                 NaN   \n",
       "\n",
       "                                          intertitres  \\\n",
       "2   Description des variables des différents\\n    ...   \n",
       "26  Les données en statistique La donnée : tentati...   \n",
       "70  Les TPE étudiées représentent 38 % des entrepr...   \n",
       "6   À l’école, les filles construisent des parcour...   \n",
       "94  Résumé Pour les immigrés, les caractéristiques...   \n",
       "54  Pour passer d’un seul mode de collecte à plusi...   \n",
       "13  La grande pauvreté, cumul de difficultés monét...   \n",
       "29  Un point sur la démographie française depuis 1...   \n",
       "98  La qualification de la source : un pré-requis ...   \n",
       "69  Au commencement, connaître les identités pour ...   \n",
       "\n",
       "                                              authors  \\\n",
       "2                                                  []   \n",
       "26  ['Pascal Rivière', 'chef de l’Inspection génér...   \n",
       "70  ['Noémie Morénillas', 'Gabriel Sklénard (Insee)']   \n",
       "6                  ['Philippe\\xa0Roussel\\xa0(Insee)']   \n",
       "94  ['Elika Athari', 'Jérôme Lê (Insee)', 'Yaël Br...   \n",
       "54  ['Éric Sigaud', 'maître d’ouvrage délégué du p...   \n",
       "13      ['Julien Blasco', 'Sébastien Picard (Insee)']   \n",
       "29  ['Elika Athari', 'Sylvain Papon', 'Isabelle Ro...   \n",
       "98  ['Franck Cotton', 'expert', 'DSI', 'Insee', 'f...   \n",
       "69  ['Joseph Préveraud de Vaumas', 'Responsable du...   \n",
       "\n",
       "                                             subtitle  \n",
       "2                                                 NaN  \n",
       "26  Impact des données externes sur la statistique...  \n",
       "70                                                NaN  \n",
       "6                                                 NaN  \n",
       "94                                                NaN  \n",
       "54                                                NaN  \n",
       "13                                                NaN  \n",
       "29                                                NaN  \n",
       "98               Industrialiser une phase essentielle  \n",
       "69  Le système national de gestion des identifiant...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil import parser\n",
    "\n",
    "# Convert date strings to datetime objects\n",
    "dates = [parser.isoparse(date_string) for date_string in data[\"date_diffusion\"]]\n",
    "\n",
    "# Sort the dates to ensure they are in chronological order\n",
    "dates.sort()\n",
    "\n",
    "# Plot the distribution of date differences\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(dates, bins=20, edgecolor='black')\n",
    "plt.title('Distribution of Date Differences (Seconds)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTION_TEMPLATE  = \"\"\"\n",
    "Réponds à la question donnée en basant ta réponse uniquement sur les informations fournises en context. \n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Réponse:\n",
    "\"\"\"\n",
    "\n",
    "INSTRUCTION_EVAL = \"\"\"\n",
    "Tu es un assistant IA spécialisé en Statistique Publique.\n",
    "Veuillez agir en tant que juge impartial et évaluer la qualité de la réponse fournie par un assistant IA à la question de l'utilisateur affichée ci-dessous. \n",
    "Pour cette évaluation, vous devez principalement considérer le critère suivant:\n",
    "\n",
    "Précision:\n",
    "    Note 1 : La réponse n’a aucun rapport avec la référence.\n",
    "    Note 2 : La réponse a une pertinence mineure mais ne correspond pas à la référence.\n",
    "    Note 3 : La réponse est moyennement pertinente mais contient des inexactitudes.\n",
    "    Note 4 : La réponse correspond à la référence mais comporte des omissions mineures.\n",
    "    Note 5 : La réponse est tout à fait exacte et correspond parfaitement à la référence.\n",
    "\n",
    "\n",
    "Commencez votre évaluation en fournissant une brève explication. Soyez le plus objectif possible. \n",
    "Après avoir fourni votre explication, vous devez évaluer la réponse sur une échelle de 1 à 5.\n",
    "Vous répondrez en FRANCAIS en respectant OBLIGATOIREMENT le format de réponse suivant : {{\"explanation\" : explication, \"score\": score}}\n",
    "\n",
    "Par exemple vous pourrez renvoyer:\n",
    "\n",
    "Votre réponse : \n",
    "{{\"explanation\" : \"La réponse donnnée ne correspond absolument pas à la réponse de référence\", \"score\": 1}}\n",
    "\n",
    "--- \n",
    "\n",
    "Voic la réponse de référence : \n",
    "{ground_truth_answer}\n",
    "\n",
    "Voici la question posée : \n",
    "{question}\n",
    "\n",
    "Voici la réponse générée :\n",
    "{generated_answer}\n",
    "\n",
    "Votre réponse : \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Needle in Haystack class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task we can ask : \n",
    "- ask a figure : Quel est le taux de chômage de la population française au premier trimestre 2024 ? \n",
    "    Answer : 7.5\n",
    "- Give a definition : Quel est la définition du coût salariale ? \n",
    "    Answer : Le coût salarial est constitué par l'ensemble des dépenses qui incombent à l'employeur pour l'emploi d'un salarié. Il se répartit en :\n",
    "    un coût direct, composé principalement des salaires bruts et différents avantages salariaux ;\n",
    "    un coût indirect formé essentiellement des cotisations patronales légales et conventionnelles et de diverses charges.\n",
    "    Dans le coût direct, les avantages salariaux correspondent notamment aux avantages en nature, à l'intéressement et à la participation.\n",
    "    Dans le coût indirect les charges autres que les cotisations patronales correspondent notamment à la formation professionnelle, aux frais de transport et aux œuvres sociales.\n",
    "- ask to retrieve multiple figures ? \n",
    "    Donne moi le taux d'inflation, le taux de croissance et le taux de chômage au premier trimestre 2024.\n",
    "    Answer : \n",
    "        - taux d'inflation : +2.2%\n",
    "        - taux de croissance : 0.2%\n",
    "        - taux de chômage : 7.5%\n",
    "\n",
    "- A combien estime t on le nombre de logement supplémentaire par an entre 2024 et 2029 ? \n",
    "    Answer : \n",
    "    L’évaluation des besoins en logements dans la région des Pays de la Loire témoigne d’une dynamique soutenue, reflétant les enjeux démographiques et économiques de la région. Les besoins sont estimés à 23 700 logements par an entre 2024 et 2029.\n",
    "- Qu'est ce que l'inflation ? \n",
    "    answer : L'inflation est la perte du pouvoir d'achat de la monnaie qui se traduit par une augmentation générale et durable des prix. \n",
    "- Comment est calculé l'inflation ? \n",
    "    answer : L’indice des prix à la consommation (IPC) est utilisé pour évaluer l’inflation.\n",
    "- Comment s'appelle le jeu de données sur les échanges extérieurs de la France ? \n",
    "    Answer : DD_CNA_ECH_EXT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Dict, Tuple\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "from tqdm import tqdm \n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, Normalize\n",
    "\n",
    "from transformers import (AutoConfig,\n",
    "                          AutoTokenizer,\n",
    "                          AutoModelForCausalLM,\n",
    "                          pipeline, BitsAndBytesConfig\n",
    "                          )\n",
    "\n",
    "import logging \n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "\n",
    "class Evaluator:\n",
    "    \"\"\"\n",
    "    Class to set up and run LLM-as-a-judge Needle-in-HayStack evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tokenizer=None, model=None,question=\"\" ,gt_answer=\"\", prompt_eval = INSTRUCTION_EVAL, \n",
    "        kwargs={\"max_new_tokens\": 250,\"return_full_text\": False,\"do_sample\": False}, verbose=False):\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "        self.question_asked = question\n",
    "        self.gt_answer = gt_answer\n",
    "        self.pipe = pipeline(\n",
    "            task=\"text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer)\n",
    "        self.prompt_template_eval = prompt_eval\n",
    "        self.kwargs = kwargs\n",
    "        self.verbose = verbose \n",
    "\n",
    "    def build_final_prompt(self, ground_truth_answer, generated_answer):\n",
    "        \"\"\"\n",
    "        Build evaluation prompt\n",
    "        \"\"\"\n",
    "        complete_prompt = self.prompt_template_eval.format(\n",
    "            question=self.question_asked,\n",
    "            ground_truth_answer=ground_truth_answer,\n",
    "            generated_answer=generated_answer\n",
    "        )\n",
    "        instructions = [\n",
    "            {\"role\": \"assistant\", \"content\": \"Tu es un assistant spécialisé en statistique publique\"},\n",
    "            {\"role\": \"user\", \"content\": complete_prompt}\n",
    "        ]\n",
    "        return self.tokenizer.apply_chat_template(instructions, tokenize=False)\n",
    "\n",
    "\n",
    "    def evaluation_parser(\n",
    "            self, evaluation: str):\n",
    "        '''\n",
    "        parsing generated evaluation to extract score and explanation\n",
    "        '''\n",
    "\n",
    "        # Define a regular expression pattern to match a dictionary string\n",
    "        pattern = r'\\{.*?\\}'\n",
    "\n",
    "        # Find all matches in the string\n",
    "        matches = re.findall(pattern, evaluation)\n",
    "\n",
    "        dictionaries = []\n",
    "        for match in matches:\n",
    "            try:\n",
    "                # Safely evaluate the string to a dictionary\n",
    "                dictionaries.append(ast.literal_eval(match))\n",
    "            except (SyntaxError, ValueError):\n",
    "                if self.verbose:\n",
    "                    logger.error(\"Error at parsing Evaluation, return default value\")\n",
    "                return {\"explanation\" : None , \"score\" : None}  # If the match is not a valid dictionary, skip it\n",
    "\n",
    "        d = dictionaries[0]\n",
    "        return {\"explanation\" : d[\"explanation\"], \"score\" : int(d[\"score\"])}\n",
    "\n",
    "    def evaluate(self, generated_answers: List[str]) -> List[str]:\n",
    "        \"\"\"\n",
    "        run in batch evaluation\n",
    "        \"\"\"\n",
    "        final_prompt = [\n",
    "            self.build_final_prompt(ground_truth_answer=self.gt_answer, generated_answer=ans) for ans in generated_answers\n",
    "            ]\n",
    "        evaluations = self.pipe(final_prompt, **self.kwargs)\n",
    "\n",
    "        return [self.evaluation_parser(eval_[0][\"generated_text\"]) for eval_ in evaluations]\n",
    "\n",
    "class LLMNeedleHaystackTester:\n",
    "    '''\n",
    "        Class to set up Needle in the haystack test ,\n",
    "        implementation inspired by https://github.com/Arize-ai/LLMTest_NeedleInAHaystack2 and https://github.com/gkamradt/LLMTest_NeedleInAHaystack\n",
    "    '''\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        needle=\"\",\n",
    "        retrieval_question=\"\",\n",
    "        results_version=1,\n",
    "        context_lengths_min=50,\n",
    "        context_lengths_max=1000,\n",
    "        context_lengths_num_intervals=10,\n",
    "        context_lengths=None,\n",
    "        document_depth_percent_min=0,\n",
    "        document_depth_percent_max=100,\n",
    "        document_depth_percent_intervals=35,\n",
    "        document_depth_percents=None,\n",
    "        llm_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "        evaluation=False,\n",
    "        prompt_template=\"\",\n",
    "        corpus_file=\"./insee_documents_sample_ref_retrieval_evaluation.csv\",\n",
    "        save_results=False,\n",
    "        final_context_length_buffer=200,\n",
    "        kwargs={\n",
    "            \"max_new_tokens\": 50,\n",
    "            \"temperature\": 0.2,\n",
    "            \"return_full_text\": False,\n",
    "            \"do_sample\": True},\n",
    "        verbose = False\n",
    "        ):\n",
    "\n",
    "        self.needle = needle\n",
    "        if not needle or not retrieval_question:\n",
    "            raise ValueError(\"Needle and retrieval_question must be provided.\")\n",
    "\n",
    "        self.context_lengths_num_intervals = context_lengths_num_intervals\n",
    "        self.document_depth_percent_intervals = document_depth_percent_intervals\n",
    "        self.retrieval_question = retrieval_question\n",
    "        self.results_version = results_version\n",
    "        self.save_results = save_results\n",
    "        self.corpus_file = corpus_file\n",
    "        self.verbose = verbose \n",
    "\n",
    "        # load llm and its tokenizer for generation\n",
    "        if llm_name is not None:\n",
    "            self.llm_name = llm_name\n",
    "            self.model, self.tokenizer = self.load_llm_model(\n",
    "                llm_name, to_load=[\"tokenizer\", \"model\"], quantization=True)\n",
    "            self.pipe = pipeline(\n",
    "                task=\"text-generation\",\n",
    "                model=self.model,\n",
    "                tokenizer=self.tokenizer)\n",
    "        else:\n",
    "            raise \"Error No LLM model loaded\"\n",
    "\n",
    "        self.kwargs = kwargs\n",
    "        self.prompt_template = prompt_template\n",
    "        self.final_context_length_buffer = self.estimate_final_context_length_buffer()\n",
    "        self.evaluator = None\n",
    "\n",
    "        if evaluation:\n",
    "            model_name_eval = \"microsoft/Phi-3-mini-128k-instruct\"\n",
    "            eval_model, eval_tokenizer = self.load_llm_model(\n",
    "                model_name_eval, to_load=[\"tokenizer\", \"model\"], quantization=True)\n",
    "            self.evaluator = Evaluator(\n",
    "                tokenizer=eval_tokenizer,\n",
    "                model=eval_model,\n",
    "                question=self.retrieval_question,\n",
    "                gt_answer=self.needle,\n",
    "                prompt_eval=INSTRUCTION_EVAL,\n",
    "                verbose = self.verbose\n",
    "            )\n",
    "\n",
    "        if context_lengths is None:\n",
    "            if context_lengths_min is None or context_lengths_max is None or context_lengths_num_intervals is None:\n",
    "                raise ValueError(\n",
    "                    \"Either context_lengths_min, context_lengths_max, context_lengths_intervals need to be filled out OR the context_lengths_list needs to be supplied.\")\n",
    "            else:\n",
    "                context_lengths = np.round(np.linspace(context_lengths_min, context_lengths_max,num=context_lengths_num_intervals, endpoint=True)).astype(int)\n",
    "                self.context_lengths = [int(x) for x in context_lengths]\n",
    "        else:\n",
    "            self.context_lengths = [int(x) for x in context_lengths]\n",
    "\n",
    "        if document_depth_percents is None:\n",
    "            if document_depth_percent_min is None or document_depth_percent_max is None or document_depth_percent_intervals is None:\n",
    "                raise ValueError(\n",
    "                    \"Either document_depth_percent_min, document_depth_percent_max, document_depth_percent_intervals need to be filled out OR the document_depth_percents needs to be supplied.\")\n",
    "            else:\n",
    "                document_depth_percents = np.round(\n",
    "                    np.linspace(\n",
    "                        document_depth_percent_min,\n",
    "                        document_depth_percent_max,\n",
    "                        num=document_depth_percent_intervals,\n",
    "                        endpoint=True)).astype(int)\n",
    "                self.document_depth_percents = [int(x) for x in document_depth_percents]\n",
    "        else:\n",
    "            self.document_depth_percents = [int(x) for x in document_depth_percents]\n",
    "\n",
    "    def load_llm_model(\n",
    "            self,\n",
    "            model_name,\n",
    "            to_load=[\n",
    "                \"tokenizer\",\n",
    "                \"model\"],\n",
    "            quantization=True) -> Tuple:\n",
    "\n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            pretrained_model_name_or_path=model_name,\n",
    "            use_fast=True,\n",
    "            device_map=\"auto\")\n",
    "\n",
    "        # Check if tokenizer has a pad_token; if not, set it to eos_token\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "        if \"model\" not in to_load:\n",
    "            return _, tokenizer\n",
    "\n",
    "        # Load LLM config\n",
    "        config = AutoConfig.from_pretrained(\n",
    "            pretrained_model_name_or_path=model_name,\n",
    "            trust_remote_code=True)\n",
    "\n",
    "        if quantization:\n",
    "            # Load quantization config\n",
    "            quantization_config = BitsAndBytesConfig(\n",
    "                load_in_4bit=True,\n",
    "                bnb_4bit_quant_type=\"nf4\",\n",
    "                bnb_4bit_compute_dtype=\"float16\",\n",
    "                bnb_4bit_use_double_quant=False,\n",
    "            )\n",
    "\n",
    "        # Load LLM\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            pretrained_model_name_or_path=model_name,\n",
    "            config=config,\n",
    "            quantization_config=quantization_config if quantization else None,\n",
    "            device_map=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "            torch_dtype=\"auto\",\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "        return model, tokenizer\n",
    "\n",
    "    def load_corpus(self, nb_sample=2) -> str:\n",
    "        if os.path.exists(self.corpus_file):\n",
    "            ext = self.corpus_file.split(\".\")[-1]\n",
    "            if ext == \"json\":\n",
    "                df = pd.read_json(self.corpus_file)\n",
    "            elif ext == \"csv\":\n",
    "                df = pd.read_csv(self.corpus_file)\n",
    "            else:\n",
    "                raise ValueError(\"File extension is not recognized\")\n",
    "\n",
    "            return ' '.join(df.sample(nb_sample)[\"content\"].astype(str))\n",
    "        else:\n",
    "            raise FileNotFoundError(\"The provided file path does not exist\")\n",
    "\n",
    "    def build_final_prompt(self, question, context):\n",
    "        complete_prompt = self.prompt_template.format(\n",
    "            context=context, question=question)\n",
    "        instructions = [\n",
    "            {\"role\": \"user\", \"content\": complete_prompt}\n",
    "        ]\n",
    "        return self.tokenizer.apply_chat_template(instructions, tokenize=False)\n",
    "\n",
    "    def estimate_final_context_length_buffer(self) -> int:\n",
    "        length_token_question = len(\n",
    "            self.encode_text_to_tokens(\n",
    "                self.retrieval_question))\n",
    "        length_token_prompt = len(\n",
    "            self.encode_text_to_tokens(\n",
    "                self.prompt_template))\n",
    "        length_token_generation = self.kwargs.get(\"max_new_tokens\", 50)\n",
    "        return length_token_question + length_token_prompt + length_token_generation + 10\n",
    "\n",
    "    def result_exists(self, context_length: int, depth_percent: int) -> bool:\n",
    "        results_dir = 'results/'\n",
    "        if not os.path.exists(results_dir):\n",
    "            return False\n",
    "\n",
    "        for filename in os.listdir(results_dir):\n",
    "            if filename.endswith('.json'):\n",
    "                file_path = os.path.join(results_dir, filename)\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        try:\n",
    "                            result = json.load(f)\n",
    "                        except json.JSONDecodeError as e:\n",
    "                            print(f\"Error decoding JSON from file {file_path}: {e}\")\n",
    "                            continue\n",
    "\n",
    "                        context_length_met = (result['context_length'] == context_length)\n",
    "                        depth_percent_met = (result['depth_percent'] == depth_percent)\n",
    "                        version_met = (result.get('version', 1) == self.results_version)\n",
    "                        model_met = (result['model'] == self.llm_name)\n",
    "\n",
    "                        if context_length_met and depth_percent_met and version_met and model_met:\n",
    "                            return True\n",
    "\n",
    "                except IOError as e:\n",
    "                    logger.error(f\"Error reading file {file_path}: {e}\")\n",
    "                    continue\n",
    "        return False\n",
    "\n",
    "    def encode_text_to_tokens(self, text: str) -> List[int]:\n",
    "        return self.tokenizer.encode(text)\n",
    "\n",
    "    def decode_tokens(\n",
    "            self,\n",
    "            tokens: List[int],\n",
    "            context_length: int = None) -> str:\n",
    "        return self.tokenizer.decode(tokens[:context_length])\n",
    "\n",
    "    def encode_and_trim(self, context: str, context_length: int) -> str:\n",
    "        tokens = self.encode_text_to_tokens(context)\n",
    "        if len(tokens) > context_length:\n",
    "            context = self.decode_tokens(tokens, context_length)\n",
    "        return context\n",
    "\n",
    "    def insert_needle(\n",
    "            self,\n",
    "            needle: str,\n",
    "            context: str,\n",
    "            depth_percent: int,\n",
    "            context_length: int) -> str:\n",
    "        tokens_needle = self.encode_text_to_tokens(needle)\n",
    "        tokens_context = self.encode_text_to_tokens(context)\n",
    "        context_length -= self.final_context_length_buffer\n",
    "\n",
    "        if len(tokens_context) + len(tokens_needle) > context_length:\n",
    "            tokens_context = tokens_context[:context_length -\n",
    "                                            len(tokens_needle)]\n",
    "\n",
    "        tokens_new_context = [42]  # initialize\n",
    "\n",
    "        if depth_percent == 100:\n",
    "            tokens_new_context = tokens_context + tokens_needle  # add element at the end\n",
    "        else:\n",
    "            insertion_point = int(len(tokens_context) * (depth_percent / 100))\n",
    "            period_tokens = self.encode_text_to_tokens(\n",
    "                '.')  # encode point character\n",
    "            while tokens_new_context and (\n",
    "                    tokens_new_context[-1] not in period_tokens):\n",
    "                insertion_point -= 1\n",
    "                tokens_new_context = tokens_context[:insertion_point]\n",
    "\n",
    "            tokens_new_context += tokens_needle + \\\n",
    "                tokens_context[insertion_point:]\n",
    "\n",
    "        new_context = self.decode_tokens(tokens_new_context)\n",
    "        return new_context\n",
    "\n",
    "    def generate_context(\n",
    "            self,\n",
    "            needle: str,\n",
    "            trim_context: str,\n",
    "            context_length: int,\n",
    "            depth_percent: int) -> str:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            needle (str): _description_\n",
    "            trim_context (str): _description_\n",
    "            context_length (int): _description_\n",
    "            depth_percent (int): _description_\n",
    "\n",
    "        Returns:\n",
    "            str: _description_\n",
    "        \"\"\"\n",
    "        return self.insert_needle(\n",
    "            needle=needle,\n",
    "            context=trim_context,\n",
    "            depth_percent=depth_percent,\n",
    "            context_length=context_length\n",
    "        )\n",
    "\n",
    "    def aggregate(self, results) -> Dict:\n",
    "        scores = [int(r['score']) for r in results]\n",
    "        return {\n",
    "            \"scores\": scores,\n",
    "            \"median\": np.median(scores),\n",
    "            \"mean\": np.mean(scores),\n",
    "            \"std_dev\": np.std(scores),\n",
    "            \"count\": len(scores)\n",
    "        }\n",
    "\n",
    "    def save(\n",
    "            self,\n",
    "            result,\n",
    "            context_length,\n",
    "            depth_percent,\n",
    "            gt_answer,\n",
    "            corpus_sample,\n",
    "            explanation=None) -> None:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            result (_type_): _description_\n",
    "            context_length (_type_): _description_\n",
    "            depth_percent (_type_): _description_\n",
    "            gt_answer (_type_): _description_\n",
    "            corpus_sample (_type_): _description_\n",
    "            explanation (_type_, optional): _description_. Defaults to None.\n",
    "        \"\"\"\n",
    "        #timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        results_dir = 'results/'\n",
    "        if not os.path.exists(results_dir):\n",
    "            os.makedirs(results_dir)\n",
    "\n",
    "        results_dict = {\n",
    "            'model': self.llm_name,\n",
    "            'needle': gt_answer,\n",
    "            'context_length': context_length,\n",
    "            'depth_percent': depth_percent,\n",
    "            'result': result,\n",
    "            'prompt_template': self.prompt_template,\n",
    "            'corpus': str(corpus_sample),\n",
    "            'version': self.results_version\n",
    "        }\n",
    "        if explanation:\n",
    "            results_dict['explanations'] = explanation\n",
    "\n",
    "        #build file name \n",
    "        filename = f'results_{self.llm_name.split(\"/\")[-1]}_{context_length}_{depth_percent}.json'\n",
    "        #turn a dictionary into a json object\n",
    "\n",
    "        with open(os.path.join(results_dir, filename), 'w') as f:\n",
    "            json.dump(results_dict, f)\n",
    "\n",
    "    def run(self, nb_corpus_sample=2):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            nb_corpus_sample (int, optional): _description_. Defaults to 2.\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        corpus_sample = self.load_corpus(nb_corpus_sample)\n",
    "\n",
    "        print(f\"{self.llm_name} tokenizes the corpus in {len(self.encode_text_to_tokens(corpus_sample))} tokens\")\n",
    "\n",
    "        all_results = {}\n",
    "\n",
    "        list_context_depth_tuples = []\n",
    "        list_final_prompts = []\n",
    "        generated_contexts = []\n",
    "        for context_length in self.context_lengths:\n",
    "            for depth_percent in self.document_depth_percents:\n",
    "\n",
    "                if not self.result_exists(context_length, depth_percent):\n",
    "                    # add only the non-already tested tuples\n",
    "                    list_context_depth_tuples.append(\n",
    "                        (context_length, depth_percent))\n",
    "                    trimmed_context = self.encode_and_trim(corpus_sample, context_length)\n",
    "                    generated_context = self.generate_context(self.needle, trimmed_context, context_length, depth_percent)\n",
    "                    generated_contexts.append(generated_context)\n",
    "                    final_prompt = self.build_final_prompt(self.retrieval_question, generated_context)\n",
    "                    list_final_prompts.append(final_prompt)\n",
    "\n",
    "        if len(list_context_depth_tuples) != 0:\n",
    "\n",
    "            print(\n",
    "                f\"\\nThe following {len(list_context_depth_tuples)} context_lenght & depth percentages will be tested : \",\n",
    "                list_context_depth_tuples\n",
    "                )\n",
    "            # run pipeline\n",
    "            answers = self.pipe(list_final_prompts, **self.kwargs)\n",
    "            generated_answers = [str(ans[0][\"generated_text\"]) for ans in answers]\n",
    "\n",
    "            #print(\"generated answer : \\n-\", \"\\n-\".join(generated_answers))\n",
    "\n",
    "            if self.evaluator:\n",
    "                evaluation_results = self.evaluator.evaluate(generated_answers)\n",
    "                #print(\"evaluation : \" , evaluation_results)\n",
    "                # extract explanations\n",
    "                for i, (context_length, depth_percent) in enumerate(list_context_depth_tuples):\n",
    "                    eval_res = evaluation_results[i]\n",
    "                    score = int(eval_res[\"score\"]) if eval_res[\"score\"] is not None else 0\n",
    "                    exp = str(eval_res[\"explanation\"]) if eval_res[\"explanation\"] is not None else \"No explanation available\"\n",
    "                    all_results[(context_length, depth_percent)] = {\"score\" : score, \"explanation\" : exp} # keep the score\n",
    "\n",
    "                    if self.save_results :\n",
    "                        self.save(result=score,\n",
    "                                context_length=context_length,\n",
    "                                depth_percent=depth_percent,\n",
    "                                gt_answer=self.needle,\n",
    "                                corpus_sample=generated_contexts[i], #add the context where the needle have been added\n",
    "                                explanation=exp)\n",
    "            else:\n",
    "                for i, (context_length, depth_percent) in enumerate(list_context_depth_tuples):\n",
    "                    all_results[(context_length, depth_percent)] = generated_answers[i]\n",
    "\n",
    "                    if self.save_results: \n",
    "                        self.save(\n",
    "                            result=generated_answers[i],\n",
    "                            context_length=context_length,\n",
    "                            depth_percent=depth_percent,\n",
    "                            gt_answer=self.needle,\n",
    "                            corpus_sample=generated_contexts[i] #add the context where the needle have been added\n",
    "                            )\n",
    "        else:\n",
    "            print(\"Skipping this configuration as result already exists\")\n",
    "\n",
    "        return all_results\n",
    "\n",
    "    def load_results(self, results_dir=\"./results\", model_name = \"mistralai/Mistral-7B-Instruct-v0.2\", version=1):\n",
    "        \"\"\"\n",
    "        load the results from a previous experiment based on  \n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        if not os.path.exists(results_dir):\n",
    "            return None \n",
    "        else: \n",
    "            \n",
    "            list_docs = os.listdir(results_dir)\n",
    "            print(f\"{len(list_docs)} documents have been found\")\n",
    "\n",
    "            for filename in tqdm(list_docs):\n",
    "                if filename.endswith('.json'):\n",
    "                    file_path = os.path.join(results_dir, filename)\n",
    "                    try:\n",
    "                        with open(file_path, 'r') as f:\n",
    "                            try:\n",
    "                                r = json.load(f)\n",
    "                            except json.JSONDecodeError as e:\n",
    "                                print(f\"Error decoding JSON from file {file_path}: {e}\")\n",
    "                                continue\n",
    "                            \n",
    "                            if \"result\" in r and \"explanations\" in r and \"model\" in r and \"version\" in r: \n",
    "                                if r[\"model\"] == model_name and r[\"version\"] ==  version: \n",
    "                                    results[(r['context_length'], r['depth_percent'])] = {\"score\" : r[\"result\"], \"explanation\" : r[\"explanations\"]}\n",
    "\n",
    "                    except IOError as e:\n",
    "                        logger.error(f\"Error reading file {file_path}: {e}\")\n",
    "                        continue\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def plot(\n",
    "            self,\n",
    "            results: Dict,\n",
    "            title= None,\n",
    "            filename=None):\n",
    "\n",
    "        if title is None:\n",
    "            title = str(self.llm_name) + \" Recall Performance\" \n",
    "\n",
    "        if filename is None:\n",
    "            filename = str(self.llm_name).split(\"/\")[-1] + \"_recall_performances.png\"\n",
    "\n",
    "        depth_percents = sorted(set(k[1] for k in results.keys()))\n",
    "        context_lengths = sorted(set(k[0] for k in results.keys()))\n",
    "        scores = np.full((len(depth_percents), len(context_lengths)), np.nan)\n",
    "\n",
    "        for (context_length, depth_percent), dict_res in results.items():\n",
    "            i = depth_percents.index(depth_percent)\n",
    "            j = context_lengths.index(context_length)\n",
    "            scores[i, j] = int(dict_res[\"score\"])\n",
    "\n",
    "        #change nan value by 0\n",
    "        scores[np.isnan(scores)] = 0\n",
    "        recall_score = np.round(np.sum(scores) / (5 * len(depth_percents) * len(context_lengths)), 1)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"#F0496E\", \"#EBB839\", \"#0CD79F\"])\n",
    "        cax = ax.matshow(\n",
    "            scores,\n",
    "            cmap=cmap,\n",
    "            norm=Normalize(vmin=0,vmax=5)\n",
    "            )\n",
    "\n",
    "        plt.colorbar(cax, fraction=0.046, pad=0.04)\n",
    "        plt.yticks(range(len(depth_percents)), depth_percents)\n",
    "        plt.xticks(range(len(context_lengths)), context_lengths, rotation=45)\n",
    "        plt.ylabel(\"Fact Placement Depth (%)\")\n",
    "        plt.xlabel(\"Haystack Size\")\n",
    "\n",
    "        plt.title(f\"{title} (Recall Score : {str(recall_score)}%)\\n {self.retrieval_question}\", fontsize = 12)\n",
    "\n",
    "        plt.savefig(filename)\n",
    "        plt.show()\n",
    "\n",
    "def generate_image(self, results: Dict, color_palette='viridis', title=None):\n",
    "        # If title is None, set a default title\n",
    "        if title is None:\n",
    "            title = str(self.llm_name) + \" Recall Performance\" \n",
    "\n",
    "        # Extract and sort unique context lengths and depth percents\n",
    "        depth_percents = sorted(set(k[1] for k in results.keys()))\n",
    "        context_lengths = sorted(set(k[0] for k in results.keys()))\n",
    "\n",
    "        # Create a DataFrame to hold the results\n",
    "        data = pd.DataFrame(index=depth_percents, columns=context_lengths)\n",
    "    \n",
    "\n",
    "        # Populate the DataFrame with results\n",
    "        for (context_length, depth_percent), res in results.items():\n",
    "            data.loc[depth_percent, context_length] = int(res[\"score\"])\n",
    "\n",
    "        #remove the nan values to get a complete heatmap \n",
    "        data.fillna(0, inplace=True)\n",
    "\n",
    "        recall_score = np.round(data.sum().sum() / (5* len(depth_percents) * len(context_lengths)),1)\n",
    "\n",
    "        # Create the figure and axis for the heatmap\n",
    "        fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "        cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"#F0496E\", \"#EBB839\", \"#0CD79F\"])\n",
    "        \n",
    "        # Generate the heatmap\n",
    "        sns.heatmap(\n",
    "            data, \n",
    "            #annot=True, \n",
    "            fmt= \"g\", #\".2f\", \n",
    "            xticklabels=\"auto\",  \n",
    "            yticklabels=\"auto\",  \n",
    "            cmap=cmap, \n",
    "            cbar=True, \n",
    "            cbar_kws={'label': 'score'}, \n",
    "            vmin=0, \n",
    "            vmax=5, \n",
    "            linewidths=.5, \n",
    "            linecolor='black', \n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        # Set axis labels and title\n",
    "        ax.set_xlabel('Haystack Size')\n",
    "        ax.set_ylabel(\"Fact Placement Depth (%)\")\n",
    "        ax.set_title(f\"{title} (Recall Score : {recall_score}%)\\n {self.retrieval_question}\", fontsize = 12)\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "        # Save the figure to the specified file path\n",
    "        file_name = str(self.llm_name).split(\"/\")[-1] + \"_recall_performances.png\"\n",
    "\n",
    "        plt.savefig(file_name)\n",
    "       \n",
    "        # Display the plot (optional)\n",
    "        plt.show()\n",
    "\n",
    "#some experiments have already been evaluated for Mistral-7B-Instruct-v0.1 and Mistral-7B-Instruct-v0.2, meta-llama/Meta-Llama-3-8B-Instruct\n",
    "#Questions already asked : \n",
    "# question about unemployement \n",
    "\n",
    "Comment est calculé l'inflation ? \n",
    "    answer : L’indice des prix à la consommation (IPC) est utilisé pour évaluer l’inflation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some experiments have been already evaluated for Mistral-7B-Instruct-v0.1, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a818e77e3a4704bf908d9a84d6df73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attenton` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4515241a260c4737b473654ca721e62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mistralai/Mistral-7B-Instruct-v0.2 tokenizes the corpus in 52468 tokens\n",
      "\n",
      "The following 100 context_lenght & depth percentages will be tested :  [(100, 0), (100, 11), (100, 22), (100, 33), (100, 44), (100, 56), (100, 67), (100, 78), (100, 89), (100, 100), (3644, 0), (3644, 11), (3644, 22), (3644, 33), (3644, 44), (3644, 56), (3644, 67), (3644, 78), (3644, 89), (3644, 100), (7189, 0), (7189, 11), (7189, 22), (7189, 33), (7189, 44), (7189, 56), (7189, 67), (7189, 78), (7189, 89), (7189, 100), (10733, 0), (10733, 11), (10733, 22), (10733, 33), (10733, 44), (10733, 56), (10733, 67), (10733, 78), (10733, 89), (10733, 100), (14278, 0), (14278, 11), (14278, 22), (14278, 33), (14278, 44), (14278, 56), (14278, 67), (14278, 78), (14278, 89), (14278, 100), (17822, 0), (17822, 11), (17822, 22), (17822, 33), (17822, 44), (17822, 56), (17822, 67), (17822, 78), (17822, 89), (17822, 100), (21367, 0), (21367, 11), (21367, 22), (21367, 33), (21367, 44), (21367, 56), (21367, 67), (21367, 78), (21367, 89), (21367, 100), (24911, 0), (24911, 11), (24911, 22), (24911, 33), (24911, 44), (24911, 56), (24911, 67), (24911, 78), (24911, 89), (24911, 100), (28456, 0), (28456, 11), (28456, 22), (28456, 33), (28456, 44), (28456, 56), (28456, 67), (28456, 78), (28456, 89), (28456, 100), (32000, 0), (32000, 11), (32000, 22), (32000, 33), (32000, 44), (32000, 56), (32000, 67), (32000, 78), (32000, 89), (32000, 100)]\n"
     ]
    }
   ],
   "source": [
    "llm_name = \"mistralai/Mistral-7B-Instruct-v0.2\" #context length : 32000\n",
    "#llm_name = \"meta-llama/Meta-Llama-3-8B-Instruct\" # context length : 8000\n",
    "\n",
    "llm_tester = LLMNeedleHaystackTester(\n",
    "        needle=\"L’indice des prix à la consommation (IPC) est utilisé pour évaluer l’inflation.\",\n",
    "        retrieval_question=\"Comment est calculé l'inflation ?\",\n",
    "        results_version=2,\n",
    "        context_lengths_min=100,\n",
    "        context_lengths_max=32000,\n",
    "        context_lengths_num_intervals=10,\n",
    "        context_lengths= None ,\n",
    "        document_depth_percent_min=0,\n",
    "        document_depth_percent_max=100,\n",
    "        document_depth_percent_intervals=10,\n",
    "        document_depth_percents=None,\n",
    "        llm_name=llm_name,\n",
    "        evaluation=True,\n",
    "        prompt_template=INSTRUCTION_TEMPLATE,\n",
    "        corpus_file=\"./insee_documents_sample_ref_retrieval_evaluation.csv\",\n",
    "        save_results=True,\n",
    "        final_context_length_buffer=200,\n",
    "        verbose = True \n",
    "    )\n",
    "\n",
    "results = llm_tester.run(nb_corpus_sample=4)\n",
    "llm_tester.plot(results=results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
