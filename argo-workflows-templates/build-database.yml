apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: build-database-
spec:
  serviceAccountName: workflow
  volumes:
    - name: dshm
      emptyDir:
        medium: Memory
        sizeLimit: 16Gi
  entrypoint: main
  arguments:
    parameters:
      - name: build-database-conf-list
        value: '[
            { "TASK": "tmp",
              "SOURCE": "tmp"
            }
            ]'

  templates:
    # Entrypoint DAG template
    - name: main
      dag:
        tasks:
          - name: build-database-with-params
            template: build-database-wt
            arguments:
              parameters:
                - name: SOURCE
                  value: "{{item.SOURCE}}"
                - name: TASK
                  value: "{{item.TASK}}"
            # Pass the inputs to the task using "withParam"
            withParam: "{{workflow.parameters.build-database-conf-list}}"

    # Now task container templates are defined
    - name: build-database-wt
      inputs:
        parameters:
          - name: SOURCE
          - name: TASK
      nodeSelector:
        nvidia.com/gpu.product: "NVIDIA-H100-PCIe"
      container:
        image: inseefrlab/onyxia-vscode-pytorch:py3.12.3-gpu
        imagePullPolicy: Always
        resources:
          requests:
            memory: 16Gi
            # cpu: 40
          limits:
            memory: 64Gi
            # cpu: 50
            nvidia.com/gpu: 1
        command: ["/bin/bash", -c]
        args:
          - |
            git clone https://github.com/InseeFrLab/llm-open-data-insee.git &&
            cd llm-open-data-insee/ &&
            git checkout db-build-pipeline &&
            pip install -r requirements-dev.txt &&
            python run_build_database.py --experiment_name BUILD_CHROMA_TEST \
              --data_raw_s3_path data/raw_data/applishare_solr_joined.parquet \
              --collection_name insee_data \
              --embedding_model OrdalieTech/Solon-embeddings-large-0.1 \
              --llm_model mistralai/Mistral-7B-Instruct-v0.2 \
              --max_pages 25
        volumeMounts:
          - mountPath: /dev/shm
            name: dshm
        env:
          # env var for s3 connexion
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                name: s3-creds
                key: accessKey
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                name: s3-creds
                key: secretKey
          - name: HF_TOKEN
            valueFrom:
              secretKeyRef:
                name: hf-token
                key: token
          - name: AWS_DEFAULT_REGION
            value: us-east-1
          - name: AWS_S3_ENDPOINT
            value: minio.lab.sspcloud.fr
          - name: MLFLOW_S3_ENDPOINT_URL
            value: https://minio.lab.sspcloud.fr
          - name: MLFLOW_TRACKING_URI
            value: https://projet-llm-insee-open-data-mlflow.user.lab.sspcloud.fr/
          - name: S3_BUCKET
            value: projet-llm-insee-open-data
