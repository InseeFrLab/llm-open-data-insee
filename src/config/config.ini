[DEFAULT]

# S3 CONFIG -------------------------------------------------------------------

experiment_name = default
aws_s3_endpoint = minio.lab.sspcloud.fr
s3_endpoint_url = https://${aws_s3_endpoint}
s3_bucket = projet-llm-insee-open-data

# LOCAL FILES -----------------------------------------------------------------

relative_data_dir = data
relative_log_dir = logs
log_file_path = ${relative_log_dir}/conversation_logs.json

# ML FLOW LOGGING -------------------------------------------------------------

mlflow_tracking_uri = https://projet-llm-insee-open-data-mlflow.user.lab.sspcloud.fr

# RAW DATA PROCESSING  --------------------------------------------------------

data_raw_s3_path = data/raw_data/applishare_solr_joined.parquet
raw_dataset_uri = s3://${s3_bucket}/${data_raw_s3_path}
markdown_split = true
use_tokenizer_to_chunk = true
separators = ['\n\n', '\n', '.', ' ', '']

rawdata_web4g = data/raw_data/applishare_solr_joined.parquet
rawdata_rmes = data/raw_data/applishare_solr_joined.parquet

rawdata_web4g_uri = s3://${s3_bucket}/${rawdata_web4g}
rawdata_rmes_uri = s3://${s3_bucket}/${rawdata_rmes}


# CORPUS BUILDING  ------------------------------------------------------------

# PARSING, PROCESSING and CHUNKING  -------------------------------------------

# Limits the number of rows
max_pages =

chunk_size = 1000
chunk_overlap = 100

# VECTOR DATABASE -------------------------------------------------------------

chroma_db_local_dir = ${relative_data_dir}/chroma_db
chroma_db_s3_dir = s3/${s3_bucket}/data/chroma_database/

collection_name = insee_data
force_rebuild = true

# MODELS USED   ---------------------------------------------------------------

# Embedding model for IR
emb_device = cuda
emb_model = OrdalieTech/Solon-embeddings-large-0.1

# LLM Model
model_name = mistralai/Mistral-7B-Instruct-v0.2


# INSTRUCTION PROMPT ----------------------------------------------------------

BASIC_RAG_PROMPT_TEMPLATE = <s>[INST]
    Instruction: Réponds à la question en te basant sur le contexte donné:

    {context}

    Question:
    {question}
    [/INST]

RAG_PROMPT_TEMPLATE = <s>[INST]
    Tu es un assistant spécialisé dans la statistique publique répondant aux questions d'agent de l'INSEE.
    Réponds en Français seulement.
    Utilise les informations obtenues dans le contexte, réponds de manière argumentée à la question posée.
    La réponse doit être développée et citer ses sources.

    Si tu ne peux pas induire ta réponse du contexte, ne réponds pas.
    Voici le contexte sur lequel tu dois baser ta réponse :
    Contexte: {context}
            ---
    Voici la question à laquelle tu dois répondre :
    Question: {question}
    [/INST]

# CHATBOT CONFIGURATION -------------------------------------------------------

CHATBOT_INSTRUCTION = En utilisant UNIQUEMENT les informations présentes dans le contexte, réponds de manière argumentée à la question posée.
    La réponse doit être développée et citer ses sources.

    Si tu ne peux pas induire ta réponse du contexte, ne réponds pas.

USER_INSTRUCTION = Voici le contexte sur lequel tu dois baser ta réponse :
    Contexte:
    {context}
    ---
    Voici la question à laquelle tu dois répondre :
    Question: {question}
